{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-16T19:07:46.892716Z",
     "iopub.status.busy": "2025-06-16T19:07:46.892412Z",
     "iopub.status.idle": "2025-06-16T19:07:47.064290Z",
     "shell.execute_reply": "2025-06-16T19:07:47.063280Z",
     "shell.execute_reply.started": "2025-06-16T19:07:46.892694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jun 16 19:07:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0             28W /  250W |       0MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T19:07:47.066170Z",
     "iopub.status.busy": "2025-06-16T19:07:47.065923Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: -c: line 1: unexpected EOF while looking for matching `\"'\n",
      "/bin/bash: -c: line 2: syntax error: unexpected end of file\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libpoppler-dev libpoppler-private-dev libpoppler118\n"
     ]
    }
   ],
   "source": [
    "!pip install \"mineru[core]>=2.0.0\n",
    "!apt-get -y install poppler-utils\n",
    "%pip install google-genai\n",
    "%pip install streamlit\n",
    "# %pip -q install huggingface_hub rank_bm25 httpx\n",
    "%pip install -Uq chromadb tiktoken\n",
    "%pip install -Uq langchain langchain-community langchain-openai langchain-groq\n",
    "%pip install -Uq python_dotenv\n",
    "%pip install -qU langchain-ollama\n",
    "%pip install -qU rank_bm25 httpx\n",
    "%pip install python-pptx\n",
    "%pip install gradio pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mineru-models-download --source huggingface --model_type pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mineru -p /kaggle/input/attention/attention_scan.pdf -o /kaggle/working/ --source local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract file PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile extract_pdf.py\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "def extract_pdf(pdf_file_path: str):\n",
    "    \"\"\"\n",
    "    Extract content from a PDF file using minerU CLI and restructure outputs\n",
    "    to match legacy structure.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path (str): Path to the input PDF file.\n",
    "        pdf_filename (str): Name of the PDF file (without .pdf).\n",
    "        output_base (str): Base directory to save outputs.\n",
    "    \"\"\"\n",
    "    # === 1Ô∏è‚É£ Call minerU CLI ===\n",
    "    cmd = f\"mineru -p {pdf_file_path} -o /kaggle/working --source local\"\n",
    "    print(f\"[INFO] Running: {cmd}\")\n",
    "    subprocess.run(cmd, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%writefile extract_pdf.py\n",
    "# import os\n",
    "# from magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader\n",
    "# from magic_pdf.data.dataset import PymuDocDataset\n",
    "# from magic_pdf.model.doc_analyze_by_custom_model import doc_analyze\n",
    "# from magic_pdf.config.enums import SupportedPdfParseMethod\n",
    "\n",
    "# def extract_pdf(pdf_file_path: str, pdf_filename: str, output_base: str = \"/kaggle/working/output\"):\n",
    "#     \"\"\"\n",
    "#     Extract content from a PDF file using minerU and save markdown and middle JSON results.\n",
    "\n",
    "#     Args:\n",
    "#         pdf_file_path (str): Path to the input PDF file.\n",
    "#         output_base (str): Base directory to save outputs (images, jsons).\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Prepare output directories\n",
    "#     images_dir = os.path.join(output_base, \"images\")\n",
    "#     jsons_dir = os.path.join(output_base, \"jsons\")\n",
    "#     local_image_dir = os.path.join(images_dir, pdf_filename)\n",
    "#     local_md_dir = os.path.join(jsons_dir, pdf_filename)\n",
    "#     image_dir = os.path.basename(local_image_dir)\n",
    "\n",
    "#     os.makedirs(local_image_dir, exist_ok=True)\n",
    "#     os.makedirs(local_md_dir, exist_ok=True)\n",
    "\n",
    "#     # Create writers\n",
    "#     image_writer = FileBasedDataWriter(local_image_dir)\n",
    "#     md_writer = FileBasedDataWriter(local_md_dir)\n",
    "\n",
    "#     # Read PDF content\n",
    "#     reader1 = FileBasedDataReader(\"\")\n",
    "#     pdf_bytes = reader1.read(pdf_file_path)\n",
    "\n",
    "#     # Create Dataset instance\n",
    "#     ds = PymuDocDataset(pdf_bytes)\n",
    "\n",
    "#     # Run inference and postprocess\n",
    "#     if ds.classify() == SupportedPdfParseMethod.OCR:\n",
    "#         infer_result = ds.apply(doc_analyze, ocr=True)\n",
    "#         pipe_result = infer_result.pipe_ocr_mode(image_writer)\n",
    "#     else:\n",
    "#         infer_result = ds.apply(doc_analyze, ocr=False)\n",
    "#         pipe_result = infer_result.pipe_txt_mode(image_writer)\n",
    "\n",
    "#     # Dump markdown and middle JSON\n",
    "    \n",
    "#     ### draw layout result on each page\n",
    "#     pipe_result.draw_layout(os.path.join(local_md_dir, f\"{pdf_filename}_layout.pdf\"))\n",
    "  \n",
    "\n",
    "#     ### dump content list\n",
    "#     pipe_result.dump_content_list(md_writer, f\"{pdf_filename}_content_list.json\", image_dir)\n",
    "\n",
    "#     ### dump markdown\n",
    "#     md_filename = f\"{pdf_filename}.md\"\n",
    "#     pipe_result.dump_md(md_writer, md_filename, image_dir)\n",
    "\n",
    "#     ### dump middle JSON\n",
    "#     middle_json_filename = f\"{pdf_filename}_middle.json\"\n",
    "#     pipe_result.dump_middle_json(md_writer, middle_json_filename)\n",
    "\n",
    "#     print(f\"[INFO] Extracted and saved to {local_md_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile prompt_builder.py\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "# Kh·ªüi t·∫°o client v·ªõi API key\n",
    "client = genai.Client(api_key=\"YOUR_GEMINI_API_KEY\")\n",
    "\n",
    "\n",
    "def summarize_image_with_gemini(image_path, caption):\n",
    "    with Image.open(image_path) as image:\n",
    "        prompt = (\n",
    "            f\"The following image is from a scientific paper, and the caption if existed is:\\n\\n\"\n",
    "            f\"{caption}\\n\\n\"\n",
    "            \"Based on both the visual content and the caption if existed, write a detailed but concise description of the image. \"\n",
    "            \"Keep the description within 100 words maximum. Use a neutral academic tone.\\n\\n\"\n",
    "            \"Then, generate a very short image caption (one single sentence, 5‚Äì15 words) for displaying below the image in a slide. \"\n",
    "            \"The short caption must be included even if you are unsure. Do not skip it.\\n\\n\"\n",
    "            \"Return the result in the following format exactly:\\n\"\n",
    "            \"**Image Description**: <your detailed description here>\\n\"\n",
    "            \"**Image Caption**: <your short caption here>\"\n",
    "        )\n",
    "\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=[image, prompt]\n",
    "        )\n",
    "        return response.text.strip()\n",
    "def summarize_table_with_gemini(caption, table_html):\n",
    "    prompt = (\n",
    "        f\"You are an assistant tasked with analyzing and summarizing tables from scientific papers. \"\n",
    "        f\"The following is an HTML table and its caption (if existed).\\n\\n\"\n",
    "        f\"Table Caption: {caption}\\n\"\n",
    "        f\"Table Data (HTML):\\n{table_html}\\n\\n\"\n",
    "        \"Analyze the table and provide a concise summary of the main results, explicitly including key numerical values. \"\n",
    "        \"Highlight which methods performed better on each dataset (TotalText and CTW-1500) based on recall (R), precision (P), and H-mean (H). \"\n",
    "        \"When identifying the best-performing methods, include the actual metric values (e.g., 'CRAFT achieved the highest recall of 85.3% on CTW-1500'). \"\n",
    "        \"Use a clear and objective academic tone. Do not restate the caption.\\n\\n\"\n",
    "        \"After the description, generate a a **very short, concise table caption (one single sentence, 5‚Äì15 words) that clearly summarizes the key insight of the table.\\n\\n\"\n",
    "        \"Return the result in the following format:\\n\"\n",
    "        \"**Table Description**: <your detailed table analysis here>\\n\"\n",
    "        \"**Table Caption**: <your concise caption here>\"\n",
    "    )\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt]\n",
    "    )\n",
    "    return response.text.strip()\n",
    "\n",
    "\n",
    "### Prompt summarize slide ###\n",
    "\n",
    "def prompt_ver1(text, equations):\n",
    "\n",
    "    eq_list = \"\\n\".join([\n",
    "        f\"- {eq.get('equation_markdown', '')} (filename: {eq.get('src', '')}\"\n",
    "        for eq in equations\n",
    "    ]) if equations else \"[None]\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are a scientific assistant helping to summarize and organize technical research documents.\n",
    "\n",
    "        Your task:\n",
    "\n",
    "        1. Summarize the content into **no more than 5 short bullet points**:\n",
    "        ‚Ä¢ Each bullet must start with the ‚Ä¢ symbol (U+2022).\n",
    "        ‚Ä¢ Use plain English and write **short, concise, clear sentences**.\n",
    "        ‚Ä¢ Focus only on the **main contributions, methods, or findings**.\n",
    "        ‚Ä¢ Avoid redundancy. Each point should convey a unique idea.\n",
    "        ‚Ä¢ Only write as many bullets as needed ‚Äî do not force 5 bullets if the content is limited.\n",
    "\n",
    "        2. Analyze the equations listed below:\n",
    "        ‚Ä¢ If a bullet point refers to or is supported by an equation, add the filename in this format: (Equation: filename.png) at the end of that bullet.\n",
    "        ‚Ä¢ Do NOT include math notation or equation content in the bullets.\n",
    "        ‚Ä¢ Only annotate relevant equations.\n",
    "\n",
    "        3. Make sure the summary reflects all key insights from the text and equations.\n",
    "        ‚Ä¢ Do NOT refer to images or tables explicitly.\n",
    "        ‚Ä¢ Use plain English. Avoid any LaTeX, symbols, or code.\n",
    "\n",
    "        **Output Format (strict):**\n",
    "        ‚Ä¢ Bullet 1  \n",
    "        ‚Ä¢ Bullet 2  \n",
    "        (up to 5 bullets)\n",
    "\n",
    "        Do NOT include any titles, explanations, or extra text.\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Raw Text:**\n",
    "        {text.strip()}\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Equations:**\n",
    "        {eq_list}\n",
    "\n",
    "        Write concise summary bullets now, annotated with equations where appropriate.\n",
    "        \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def prompt_ver2(text, equations, images):\n",
    "    import os\n",
    "\n",
    "    eq_list = \"\\n\".join([\n",
    "        f\"- {eq.get('equation_markdown', '')} (filename: {eq.get('src', '')}\"\n",
    "        for eq in equations\n",
    "    ]) if equations else \"[None]\"\n",
    "\n",
    "    max_section = len(images) + 1\n",
    "\n",
    "    figure_list = []\n",
    "    table_list = []\n",
    "    for img in images:\n",
    "        alt = img.get(\"alt\", \"\")\n",
    "        name = img.get(\"src\", \"\")\n",
    "        caption = img.get(\"caption\", \"\").strip()\n",
    "        item_str = f\"(Caption: {caption}) - (Filename: {name})\"\n",
    "        if alt.lower() == \"table\":\n",
    "            table_list.append(item_str)\n",
    "        else:\n",
    "            figure_list.append(item_str)\n",
    "\n",
    "    img_list = \"\\n\".join(figure_list) if figure_list else \"[None]\"\n",
    "    table_list_str = \"\\n\".join(table_list) if table_list else \"[None]\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are a scientific assistant helping to summarize and organize technical research documents.\n",
    "\n",
    "        Your task is as follows:\n",
    "\n",
    "        **Input:**\n",
    "        - A raw text block from a scientific paper (see below).\n",
    "        - A list of related equations in LaTeX/Markdown format (with filenames).\n",
    "        - A list of related figures and tables (each with a caption and filename).\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Your Goals:**\n",
    "\n",
    "        1. **Summarize** the input text into concise, clear bullet points.\n",
    "        2. **Organize** the bullets into logical sections:\n",
    "        - Each section should have a header: `### Section N: Title of section`\n",
    "        - Each section can have **up to 5 bullets**.\n",
    "        - Each section can reference **at most 2 visuals** (images or tables).\n",
    "        - The **total number of sections must not exceed {max_section}**.\n",
    "\n",
    "        3. **Annotate** each bullet with any clearly related visual or equation:\n",
    "        - Use format: `(Image: figure1.png, figure2.jpg) or (Table: table1.png) or (Equation: 1.png)`\n",
    "        - Use at most 2 references per bullet.\n",
    "        - If no relevant visual/equation applies, leave it untagged.\n",
    "        \n",
    "\n",
    "        **Coverage Requirement:**\n",
    "\n",
    "        - Make sure that **each image, table, and equation is referenced by at least one bullet** if relevant.\n",
    "        - Distribute references across sections so that **no image/table/equation is left out unnecessarily**.\n",
    "        - Avoid forcing unrelated visuals into bullets ‚Äî only include them where they naturally fit.\n",
    "\n",
    "\n",
    "        **Formatting Guidelines:**\n",
    "        - Use natural language to explain all ideas ‚Äî do NOT include any mathematical notation, LaTeX, or special symbols (like $...$)\n",
    "        - Each bullet must be a standalone factual summary.\n",
    "        - Do not reuse or rephrase raw text ‚Äî rewrite clearly.\n",
    "        - Do not invent filenames or captions.\n",
    "        - Do not add more than {max_section} sections.\n",
    "\n",
    "\n",
    "        **Raw Text:**\n",
    "        {text.strip()}\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Equations:**\n",
    "        {eq_list}\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Figures:**\n",
    "        {img_list}\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Tables:**\n",
    "        {table_list_str}\n",
    "\n",
    "        ---\n",
    "\n",
    "        Now write the summary bullets, organized by section, and annotate related visuals/equations accordingly.\n",
    "        \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Json Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile process_json_data.py\n",
    "import json\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from google import genai\n",
    "import uuid\n",
    "from langchain.schema import Document\n",
    "from prompt_builder import summarize_image_with_gemini, summarize_table_with_gemini\n",
    "\n",
    "def split_chunks_by_title(data, max_chunk_len=1000):\n",
    "    chunks = []\n",
    "    current_title = \"\"\n",
    "    current_chunk_texts = []\n",
    "    i = 0\n",
    "\n",
    "    def get_text_len(text_list):\n",
    "        return sum(len(t.strip()) for t in text_list)\n",
    "\n",
    "    def flush_chunk():\n",
    "        nonlocal current_chunk_texts\n",
    "        if not current_chunk_texts:\n",
    "            return\n",
    "\n",
    "        full_text = \"\\n\".join(current_chunk_texts).strip()\n",
    "        if not full_text:\n",
    "            return\n",
    "\n",
    "        # N·∫øu l√† ph·∫ßn Reference, chia nh·ªè theo d√≤ng\n",
    "        if \"reference\" in current_title.lower() or \"t√†i li·ªáu tham kh·∫£o\" in current_title.lower():\n",
    "            lines = full_text.split(\"\\n\")\n",
    "            buffer = []\n",
    "            buffer_len = 0\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                if buffer_len + len(line) > max_chunk_len:\n",
    "                    chunks.append(f\"{current_title.strip()}\\n\" + \"\\n\".join(buffer).strip())\n",
    "                    buffer = [line]\n",
    "                    buffer_len = len(line)\n",
    "                else:\n",
    "                    buffer.append(line)\n",
    "                    buffer_len += len(line)\n",
    "            if buffer:\n",
    "                chunks.append(f\"{current_title.strip()}\\n\" + \"\\n\".join(buffer).strip())\n",
    "        else:\n",
    "            chunks.append(f\"{current_title.strip()}\\n{full_text}\")\n",
    "\n",
    "        current_chunk_texts.clear()\n",
    "\n",
    "    while i < len(data):\n",
    "        entry = data[i]\n",
    "        temp_texts = []\n",
    "\n",
    "        # N·∫øu l√† ti√™u ƒë·ªÅ\n",
    "        if entry[\"type\"] == \"text\" and entry.get(\"text_level\") == 1:\n",
    "            # G·ªôp c√°c ti√™u ƒë·ªÅ li√™n ti·∫øp\n",
    "            new_title = entry[\"text\"].strip()\n",
    "            i += 1\n",
    "            while i < len(data) and data[i].get(\"text_level\") == 1:\n",
    "                new_title += \"\\n\" + data[i][\"text\"].strip()\n",
    "                i += 1\n",
    "            flush_chunk()\n",
    "            current_title = new_title\n",
    "            continue\n",
    "\n",
    "        # X·ª≠ l√Ω ph∆∞∆°ng tr√¨nh\n",
    "        if entry[\"type\"] == \"equation\":\n",
    "            if i > 0 and data[i-1][\"type\"] == \"text\":\n",
    "                prev_text = data[i-1][\"text\"].strip()\n",
    "                if not current_chunk_texts or current_chunk_texts[-1] != prev_text:\n",
    "                    temp_texts.append(prev_text)\n",
    "            temp_texts.append(entry[\"text\"].strip())\n",
    "            if i + 1 < len(data) and data[i+1][\"type\"] == \"text\":\n",
    "                temp_texts.append(data[i+1][\"text\"].strip())\n",
    "                i += 1\n",
    "\n",
    "        elif entry[\"type\"] == \"text\":\n",
    "            text = entry[\"text\"].strip()\n",
    "            if text:\n",
    "                temp_texts.append(text)\n",
    "\n",
    "        current_chunk_texts.extend(temp_texts)\n",
    "\n",
    "        # N·∫øu chunk hi·ªán t·∫°i v∆∞·ª£t qu√° max length\n",
    "        if get_text_len(current_chunk_texts) > max_chunk_len:\n",
    "            j = i + 1\n",
    "            while j < len(data):\n",
    "                next_entry = data[j]\n",
    "                if next_entry.get(\"text_level\") == 1:\n",
    "                    break\n",
    "\n",
    "                lookahead_temp = []\n",
    "\n",
    "                if next_entry[\"type\"] == \"equation\":\n",
    "                    if j > 0 and data[j-1][\"type\"] == \"text\":\n",
    "                        prev_text = data[j-1][\"text\"].strip()\n",
    "                        if not current_chunk_texts or current_chunk_texts[-1] != prev_text:\n",
    "                            lookahead_temp.append(prev_text)\n",
    "                    lookahead_temp.append(next_entry[\"text\"].strip())\n",
    "                    if j + 1 < len(data) and data[j+1][\"type\"] == \"text\":\n",
    "                        lookahead_temp.append(data[j+1][\"text\"].strip())\n",
    "                        j += 1\n",
    "                elif next_entry[\"type\"] == \"text\":\n",
    "                    lookahead_temp.append(next_entry[\"text\"].strip())\n",
    "\n",
    "                if get_text_len(lookahead_temp) + get_text_len(current_chunk_texts) <= max_chunk_len:\n",
    "                    current_chunk_texts.extend(lookahead_temp)\n",
    "                    j += 1\n",
    "                    i = j\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "            flush_chunk()\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    flush_chunk()\n",
    "    return chunks\n",
    "\n",
    "def process_json_data(content_list_json, images_root):\n",
    "    with open(content_list_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    chunks = split_chunks_by_title(data)\n",
    "\n",
    "    image_summaries = []\n",
    "    image_captions = []\n",
    "    for item in data:\n",
    "        if item['type'] == 'image':\n",
    "            full_path = os.path.join(images_root, item['img_path'])\n",
    "            caption = item.get('img_caption', '')\n",
    "            try:\n",
    "                response = summarize_image_with_gemini(full_path, caption)\n",
    "                # T√°ch ph·∫ßn m√¥ t·∫£ v√† caption t·ª´ response\n",
    "                description = \"\"\n",
    "                short_caption = \"\"\n",
    "                for line in response.splitlines():\n",
    "                    if line.startswith(\"**Image Description**:\"):\n",
    "                        description = line.replace(\"**Image Description**:\", \"\").strip()\n",
    "                    elif line.startswith(\"**Image Caption**:\"):\n",
    "                        short_caption = line.replace(\"**Image Caption**:\", \"\").strip()\n",
    "                image_summaries.append(description)\n",
    "                image_captions.append(short_caption)\n",
    "            except Exception as e:\n",
    "                image_summaries.append(str(e))\n",
    "                image_captions.append(\"\")\n",
    "\n",
    "    table_summaries = []\n",
    "    table_captions = []\n",
    "    for item in data:\n",
    "        if item['type'] == 'table':\n",
    "            caption = item.get('table_caption', '')\n",
    "            html = item['table_body']\n",
    "            try:\n",
    "                response = summarize_table_with_gemini(caption, html)\n",
    "                # T√°ch ph·∫ßn m√¥ t·∫£ v√† caption t·ª´ response\n",
    "                description = \"\"\n",
    "                short_caption = \"\"\n",
    "                for line in response.splitlines():\n",
    "                    if line.startswith(\"**Table Description**:\"):\n",
    "                        description = line.replace(\"**Table Description**:\", \"\").strip()\n",
    "                    elif line.startswith(\"**Table Caption**:\"):\n",
    "                        short_caption = line.replace(\"**Table Caption**:\", \"\").strip()\n",
    "                table_summaries.append(description)\n",
    "                table_captions.append(short_caption)\n",
    "            except Exception as e:\n",
    "                table_summaries.append(str(e))\n",
    "                table_captions.append(\"\")\n",
    "\n",
    "    # 3. H√†m chu·∫©n b·ªã documents t·ª´ summaries\n",
    "    def create_summary_documents(summaries, data_type):\n",
    "        return [\n",
    "            Document(page_content=summary, metadata={\"type\": data_type, \"doc_id\": str(uuid.uuid4())})\n",
    "            for summary in summaries\n",
    "        ]\n",
    "\n",
    "    # Chuy·ªÉn ƒë·ªïi summaries th√†nh documents\n",
    "    text_summary_docs = create_summary_documents(chunks, \"text_summary\")\n",
    "    image_summary_docs = create_summary_documents(image_summaries, \"image_summary\")\n",
    "    table_summary_docs = create_summary_documents(table_summaries, \"table_summary\")\n",
    "    all_docs_summary = text_summary_docs + image_summary_docs + table_summary_docs\n",
    "\n",
    "    return all_docs_summary,image_captions,table_captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile reranker.py\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-v2-m3\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"BAAI/bge-reranker-v2-m3\").to(device).eval()\n",
    "\n",
    "\n",
    "def get_top_k_docs(query, docs, k=1):\n",
    "    documents = [doc[\"document\"] if isinstance(doc, dict) else str(doc) for doc in docs]\n",
    "\n",
    "    if not query or not documents:\n",
    "        return []\n",
    "\n",
    "    scores = []\n",
    "    batch_size = 4  # d√πng k l√†m batch size\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(documents), batch_size):\n",
    "            batch_docs = documents[i:i + batch_size]\n",
    "            pairs = [[query, doc] for doc in batch_docs]\n",
    "            inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "            logits = model(**inputs, return_dict=True).logits.view(-1)\n",
    "            scores.extend(logits.tolist())\n",
    "\n",
    "    results = [{\"document\": doc, \"score\": float(round(score, 4))} for doc, score in zip(documents, scores)]\n",
    "    top_k_docs = sorted(results, key=lambda x: x[\"score\"], reverse=True)[:k]\n",
    "    return top_k_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BGE-M3 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# Kh·ªüi t·∫°o embedding\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile create_slide.py\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "import os\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from prompt_builder import prompt_ver1, prompt_ver2\n",
    "from google import genai\n",
    "# Kh·ªüi t·∫°o client v·ªõi API key\n",
    "client = genai.Client(api_key=\"YOUR_GEMINI_API_KEY\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "def copy_unique_equation_images(pdf_name, middle_json, output_root=\"/kaggle/working/\"):\n",
    "    \n",
    "    save_dir = os.path.join(output_root, pdf_name, \"auto\", \"images\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    with open(middle_json, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    image_paths = []\n",
    "\n",
    "    for page in data.get(\"pdf_info\", []):\n",
    "        # C√°c tool th∆∞·ªùng g·ªçi l√† \"blocks\" ho·∫∑c \"preproc_blocks\"\n",
    "        blocks = page.get(\"blocks\", []) + page.get(\"preproc_blocks\", [])\n",
    "        for block in blocks:\n",
    "            if block.get(\"type\") == \"interline_equation\":\n",
    "                lines = block.get(\"lines\", [])\n",
    "                for line in lines:\n",
    "                    spans = line.get(\"spans\", [])\n",
    "                    for span in spans:\n",
    "                        if span.get(\"type\") == \"interline_equation\":\n",
    "                            image_path = span.get(\"image_path\")\n",
    "                            if image_path:\n",
    "                                image_paths.append(image_path)\n",
    "\n",
    "    print(f\"üîç Found {len(image_paths)} raw image paths in {middle_json}\")\n",
    "    unique_image_paths = list(dict.fromkeys(image_paths))\n",
    "    print(\"Image paths after deduplication:\", unique_image_paths )\n",
    "\n",
    "    for idx, img_path_raw in enumerate(unique_image_paths):\n",
    "        imgpath = os.path.join(save_dir, img_path_raw)\n",
    "        if os.path.exists(img_path):\n",
    "            dst = os.path.join(save_dir, f\"{idx}.png\")\n",
    "            shutil.copy(img_path, dst)\n",
    "            print(f\"‚úÖ Copied: {img_path} -> {dst}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Not found: {img_path}\")\n",
    "\n",
    "    print(f\"üéâ Done! Total unique equations copied: {len(unique_image_paths)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_markdown(filepath, content_list_json, pdf_filename, image_captions, table_captions):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    # 1. ƒê·ªçc danh s√°ch b·∫£ng t·ª´ JSON\n",
    "    with open(content_list_json, 'r', encoding='utf-8') as f:\n",
    "        raw_table_data = json.load(f)\n",
    "\n",
    "    table_images = []\n",
    "    table_idx = 0\n",
    "    for item in raw_table_data:\n",
    "        if item.get(\"type\") == \"table\":\n",
    "            path = item.get(\"img_path\", \"\")\n",
    "            # S·ª≠ d·ª•ng short caption t·ª´ table_captions\n",
    "            short_caption = table_captions[table_idx] if table_idx < len(table_captions) else \"\"\n",
    "            caption = f\"Table {table_idx + 1}. {short_caption}\" if short_caption else f\"Table {table_idx + 1}\"\n",
    "            table_images.append({\"path\": path, \"caption\": caption})\n",
    "            table_idx += 1\n",
    "\n",
    "    global_figures = []\n",
    "    global_tables = table_images\n",
    "\n",
    "    header_pattern = re.compile(r'(#{1,4})\\s+(.*)')\n",
    "    blocks = []\n",
    "    current_block = None\n",
    "\n",
    "    lines = content.splitlines()\n",
    "    i = 0\n",
    "    figure_idx = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i]\n",
    "        header_match = header_pattern.match(line)\n",
    "\n",
    "        if header_match:\n",
    "            if current_block:\n",
    "                blocks.append(current_block)\n",
    "            level = len(header_match.group(1))\n",
    "            title = header_match.group(2).strip()\n",
    "            current_block = {\n",
    "                'heading': title,\n",
    "                'level': level,\n",
    "                'text': '',\n",
    "                'equations': [],\n",
    "                'images': []\n",
    "            }\n",
    "        elif current_block:\n",
    "            # ·∫¢nh markdown\n",
    "            img_match = re.match(r'!\\[(.*?)\\]\\((.*?)\\)', line)\n",
    "            if img_match:\n",
    "                alt, src = img_match.groups()\n",
    "                # Caption ∆∞u ti√™n t·ª´ image_captions\n",
    "                short_caption = image_captions[figure_idx] if figure_idx < len(image_captions) else \"\"\n",
    "                caption = f\"Figure {figure_idx + 1}. {short_caption}\" if short_caption else f\"Figure {figure_idx + 1}\"\n",
    "                figure_info = {'alt': alt, 'src': src, 'caption': caption}\n",
    "                current_block['images'].append(figure_info)\n",
    "                global_figures.append(figure_info)\n",
    "                figure_idx += 1\n",
    "            elif '<table' in line:\n",
    "                if len(global_tables) > 0:\n",
    "                    table_info = global_tables[len(global_tables) - len(table_images)]\n",
    "                    current_block['images'].append({\n",
    "                        'alt': 'table',\n",
    "                        'src': table_info['path'],\n",
    "                        'caption': table_info['caption']\n",
    "                    })\n",
    "                    table_images.pop(0)\n",
    "            else:\n",
    "                current_block['text'] += line + '\\n'\n",
    "        i += 1\n",
    "\n",
    "    if current_block:\n",
    "        blocks.append(current_block)\n",
    "\n",
    "    # 3. Equation ‚Üí l∆∞u path ·∫£nh + markdown g·ªëc\n",
    "    eq_counter = 0\n",
    "    for block in blocks:\n",
    "        matches = list(re.finditer(r'\\$\\$(.*?)\\$\\$', block['text'], re.DOTALL))\n",
    "        block['equations'] = []\n",
    "        for match in matches:\n",
    "            eq_text = match.group(0)\n",
    "            eq_name = f\"{eq_counter}.png\"\n",
    "            eq_path = os.path.join(os.path.join(\"/kaggle/working/\", pdf_filename, \"auto/equations\"), eq_name)\n",
    "            block['equations'].append({\n",
    "                \"src\": eq_path,\n",
    "                \"equation_markdown\": eq_text\n",
    "            })\n",
    "            eq_counter += 1\n",
    "\n",
    "    # 4. Th√™m ·∫£nh v√† b·∫£ng ƒë∆∞·ª£c tham chi·∫øu trong text\n",
    "    fig_ref_pattern = re.compile(r'(?:Fig\\.|Figure)\\s*\\.?\\s*(\\d+)', re.IGNORECASE)\n",
    "    table_ref_pattern = re.compile(r'Table\\s*\\.?\\s*(\\d+)', re.IGNORECASE)\n",
    "\n",
    "    for block in blocks:\n",
    "        referenced = set()\n",
    "\n",
    "        for fig_match in fig_ref_pattern.findall(block['text']):\n",
    "            index = int(fig_match) - 1\n",
    "            if 0 <= index < len(global_figures):\n",
    "                fig_info = global_figures[index]\n",
    "                fig_id = (fig_info['src'], fig_info['caption'])\n",
    "                if fig_id not in referenced:\n",
    "                    block['images'].append(fig_info)\n",
    "                    referenced.add(fig_id)\n",
    "\n",
    "        for table_match in table_ref_pattern.findall(block['text']):\n",
    "            index = int(table_match) - 1\n",
    "            if 0 <= index < len(global_tables):\n",
    "                table_info = global_tables[index]\n",
    "                table_data = {\n",
    "                    'alt': 'table',\n",
    "                    'src': table_info['path'],\n",
    "                    'caption': table_info['caption']\n",
    "                }\n",
    "                table_id = (table_data['src'], table_data['caption'])\n",
    "                if table_id not in referenced:\n",
    "                    block['images'].append(table_data)\n",
    "                    referenced.add(table_id)\n",
    "\n",
    "        # 5. Lo·∫°i b·ªè tr√πng l·∫∑p theo `src`\n",
    "        seen = set()\n",
    "        unique_images = []\n",
    "        for img in block['images']:\n",
    "            key = img.get('src')\n",
    "            if key and key not in seen:\n",
    "                unique_images.append(img)\n",
    "                seen.add(key)\n",
    "        block['images'] = unique_images\n",
    "    print(\"Image cap:\", image_captions)   \n",
    "    return blocks\n",
    "\n",
    "def update_levels_from_heading_text(blocks):\n",
    "    cleaned_blocks = []\n",
    "\n",
    "    for block in blocks:\n",
    "        heading = block['heading'].strip()\n",
    "        # Lo·∫°i c√°c block: abstract, references, appendix (d∆∞·ªõi m·ªçi h√¨nh th·ª©c)\n",
    "        heading_lower = heading.lower()\n",
    "\n",
    "        # B·ªè qua abstract, references, appendix, appendices, appendix a, etc.\n",
    "        if (\n",
    "            heading_lower in {\"abstract\", \"references\", \"appendix\", \"appendices\"} or\n",
    "            heading_lower.startswith(\"appendix\") or\n",
    "            heading_lower.startswith(\"a.\")\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # N·∫øu g·∫∑p \"Conclusion\" th√¨ x·ª≠ l√Ω block n√†y r·ªìi d·ª´ng\n",
    "        if \"conclusion\" in heading.lower():\n",
    "            # C·∫≠p nh·∫≠t level n·∫øu c√≥ ƒë√°nh s·ªë\n",
    "            match = re.match(r'^(\\d+(\\.\\d+)*)', heading)\n",
    "            if match:\n",
    "                block['level'] = match.group(1).count('.') + 1\n",
    "            else:\n",
    "                block['level'] = 1\n",
    "\n",
    "            cleaned_blocks.append(block)\n",
    "            break  # D·ª´ng sau khi x·ª≠ l√Ω conclusion\n",
    "\n",
    "        # C·∫≠p nh·∫≠t level n·∫øu c√≥ ƒë√°nh s·ªë\n",
    "        match = re.match(r'^(\\d+(\\.\\d+)*)', heading)\n",
    "        if match:\n",
    "            block['level'] = match.group(1).count('.') + 1\n",
    "        else:\n",
    "            block['level'] = 1\n",
    "\n",
    "        cleaned_blocks.append(block)\n",
    "\n",
    "    return cleaned_blocks\n",
    "\n",
    "\n",
    "### Create Content Slide ###\n",
    "def create_content_slide(blocks):\n",
    "    content_lines = []\n",
    "    for block in blocks:\n",
    "        level = block['level']\n",
    "        heading = block['heading'].strip()\n",
    "\n",
    "        # Lo·∫°i b·ªè ti·ªÅn t·ªë \"1 \" n·∫øu c√≥ do l·ªói Markdown parser\n",
    "        heading = re.sub(r'^1\\s+', '', heading)\n",
    "\n",
    "        indent = '          ' * (level - 1) # m·ªói level th·ª•t v√†o 2 space\n",
    "        content_lines.append(f\"{indent}{heading}\")\n",
    "\n",
    "    return {\n",
    "        'heading': 'Content',\n",
    "        'level': 1,\n",
    "        'text': '\\n'.join(content_lines),\n",
    "        'equations': [],\n",
    "        'images': []\n",
    "    }\n",
    "\n",
    "### Parse into sub sections ###\n",
    "def parse_summary_into_sections(summarized_text, block):\n",
    "    sections = []\n",
    "    current_section = None\n",
    "    current_bullets = []\n",
    "    image_filenames = set()\n",
    "\n",
    "    image_lookup = {img[\"src\"]: img for img in block.get(\"images\", [])}\n",
    "\n",
    "    lines = summarized_text.strip().splitlines()\n",
    "    heading = block[\"heading\"]\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"### Section\"):\n",
    "            # L∆∞u section c≈©\n",
    "            if current_section and current_bullets:\n",
    "                sections.append({\n",
    "                    \"heading\": heading,\n",
    "                    \"sub_heading\": current_section,\n",
    "                    \"text\": \"\\n\".join(current_bullets).strip(),\n",
    "                    \"images\": [\n",
    "                        image_lookup[fname]\n",
    "                        for fname in sorted(image_filenames)\n",
    "                        if fname in image_lookup\n",
    "                    ]\n",
    "                })\n",
    "\n",
    "            # Reset cho section m·ªõi\n",
    "            current_section = line.replace(\"###\", \"\").strip()\n",
    "            current_bullets = []\n",
    "            image_filenames = set()\n",
    "\n",
    "        elif line.startswith(\"*\"):\n",
    "            content = line[1:].strip()\n",
    "\n",
    "            # T√¨m ·∫£nh/table li√™n quan\n",
    "            related_imgs = re.findall(r\"\\(Image: ([^)]+)\\)\", content)\n",
    "            related_tables = re.findall(r\"\\(Table: ([^)]+)\\)\", content)\n",
    "            image_filenames.update(related_imgs + related_tables)\n",
    "\n",
    "            # Lo·∫°i b·ªè ph·∫ßn li√™n quan image/table kh·ªèi n·ªôi dung\n",
    "            clean_content = re.sub(r\"\\(Image: [^)]+\\)\", \"\", content)\n",
    "            clean_content = re.sub(r\"\\(Table: [^)]+\\)\", \"\", clean_content).strip()\n",
    "\n",
    "            current_bullets.append(clean_content)\n",
    "\n",
    "    # L∆∞u section cu·ªëi\n",
    "    if current_section and current_bullets:\n",
    "        sections.append({\n",
    "            \"heading\": heading,\n",
    "            \"sub_heading\": current_section,\n",
    "            \"text\": \"\\n\".join(current_bullets).strip(),\n",
    "            \"images\": [\n",
    "                image_lookup[fname]\n",
    "                for fname in sorted(image_filenames)\n",
    "                if fname in image_lookup\n",
    "            ]\n",
    "        })\n",
    "\n",
    "    return sections\n",
    "\n",
    "def summarize_block(block):\n",
    "    \"\"\"\n",
    "    Summarize a single block using either prompt_ver1 or prompt_ver2 based on number of images.\n",
    "    Returns a list of summarized blocks.\n",
    "    \"\"\"\n",
    "    text = block['text'].strip()\n",
    "    if not text:\n",
    "        print(f\"Block ('{block['heading']}') is empty, skipping.\")\n",
    "        return []\n",
    "\n",
    "    print(f\"\\n‚è≥ Summarizing block ‚Äî {block['heading'][:30]}...\")\n",
    "    block_summaries = []\n",
    "\n",
    "    # Count number of images\n",
    "    num_images = len(block.get('images', []))\n",
    "    num_equations = len(block.get('equations', []))\n",
    "    \n",
    "    try:\n",
    "        if num_images > 2 or num_equations > 3:\n",
    "            # Use prompt_ver2 for blocks with >2 images\n",
    "            prompt = prompt_ver2(\n",
    "                text=text,\n",
    "                equations=block.get(\"equations\", []),\n",
    "                images=block.get(\"images\", [])\n",
    "            )\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                contents=prompt\n",
    "            )\n",
    "            summarized = response.text.strip()\n",
    "            \n",
    "            # Split into sections\n",
    "            sections = parse_summary_into_sections(summarized, block)\n",
    "            block_summaries.extend(sections)\n",
    "            \n",
    "        else:\n",
    "            # Use prompt_ver1 for blocks with <=2 images\n",
    "            prompt = prompt_ver1(\n",
    "                text=text,\n",
    "                equations=block.get(\"equations\", [])\n",
    "            )\n",
    "            \n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.0-flash\", \n",
    "                contents=prompt\n",
    "            )\n",
    "            time.sleep(2)\n",
    "            summarized = response.text.strip()\n",
    "            \n",
    "            # Create a single block with the summary\n",
    "            summary_block = {\n",
    "                \"heading\": block[\"heading\"],\n",
    "                \"text\": summarized,\n",
    "                \"equations\": block.get(\"equations\", []),\n",
    "                \"images\": block.get(\"images\", [])\n",
    "            }\n",
    "            block_summaries.append(summary_block)\n",
    "\n",
    "        print(f\"‚úÖ Done summarizing block\")\n",
    "        return block_summaries\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error summarizing block: {e}\")\n",
    "        return [{\n",
    "            \"heading\": block[\"heading\"],\n",
    "            \"text\": \"[Summary failed]\",\n",
    "            \"equations\": block.get(\"equations\", []),\n",
    "            \"images\": block.get(\"images\", [])\n",
    "        }]\n",
    "    \n",
    "def summarize_blocks(blocks, start_idx=0, max_blocks=None, sleep_time=1.5):\n",
    "    \"\"\"\n",
    "    Summarize multiple blocks using the summarize_block function.\n",
    "    Returns a list of all summarized blocks.\n",
    "    \"\"\"\n",
    "    end_idx = len(blocks) if max_blocks is None else start_idx + max_blocks\n",
    "    all_summarized_blocks = []\n",
    "\n",
    "    for i in range(start_idx, end_idx):\n",
    "        block = blocks[i]\n",
    "        summarized_blocks = summarize_block(block)\n",
    "        all_summarized_blocks.extend(summarized_blocks)\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    return all_summarized_blocks\n",
    "\n",
    "### Create Slide ###\n",
    "def set_text_with_font(text_frame, text, font_size=16, align=PP_ALIGN.LEFT):\n",
    "    text_frame.word_wrap = True\n",
    "    text_frame.clear()\n",
    "    for line in text.strip().splitlines():\n",
    "        p = text_frame.add_paragraph()\n",
    "        p.text = line\n",
    "        p.font.size = Pt(font_size)\n",
    "        p.alignment = align\n",
    "\n",
    "def add_bullets_with_equations(shapes, left, top, width, text, max_image_width=Inches(3.5)):\n",
    "    \"\"\"\n",
    "    M·ªói bullet n·∫±m trong m·ªôt textbox ri√™ng, cao kho·∫£ng 0.8 inch (t∆∞∆°ng ƒë∆∞∆°ng ~4 d√≤ng).\n",
    "    Kh√¥ng c√≥ margin trong text_frame. C√≥ h·ªó tr·ª£ ·∫£nh ph∆∞∆°ng tr√¨nh (Equation: path).\n",
    "    \"\"\"\n",
    "    eq_pattern = re.compile(r'\\(Equation:\\s*([^\\)]+)\\)')\n",
    "    current_top = top\n",
    "    bullet_height = Inches(1)\n",
    "    spacing = Inches(0.2)\n",
    "\n",
    "    bullets = [line.strip() for line in text.split('\\n') if line.strip()]\n",
    "    for bullet in bullets:\n",
    "        eq_match = eq_pattern.search(bullet)\n",
    "        eq_path = None\n",
    "        if eq_match:\n",
    "            eq_path = eq_match.group(1).strip()\n",
    "            bullet = eq_pattern.sub('', bullet).strip()\n",
    "\n",
    "        # T·∫°o textbox ri√™ng cho t·ª´ng bullet\n",
    "        text_box = shapes.add_textbox(left, current_top, width, bullet_height)\n",
    "        tf = text_box.text_frame\n",
    "        tf.word_wrap = True\n",
    "        tf.clear()\n",
    "\n",
    "        # B·ªè h·∫øt margin n·∫øu mu·ªën\n",
    "        tf.margin_left = 0\n",
    "        tf.margin_right = 0\n",
    "        tf.margin_top = 0\n",
    "        tf.margin_bottom = 0\n",
    "\n",
    "        p = tf.add_paragraph()\n",
    "        p.text = bullet\n",
    "        p.font.size = Pt(16)\n",
    "\n",
    "        current_top += bullet_height + spacing\n",
    "\n",
    "        # Th√™m ·∫£nh ph∆∞∆°ng tr√¨nh n·∫øu c√≥\n",
    "        if eq_path and os.path.exists(eq_path):\n",
    "            pic = shapes.add_picture(eq_path, left + (width - max_image_width) / 2, current_top, width=max_image_width)\n",
    "            pic_height = pic.height.inches\n",
    "            current_top += Inches(pic_height) + spacing\n",
    "        elif eq_path:\n",
    "            print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh ph∆∞∆°ng tr√¨nh: {eq_path}\")\n",
    "\n",
    "    return current_top\n",
    "\n",
    "\n",
    "def create_presentation(blocks, pdf_filename, output_file=\"output.pptx\"):\n",
    "    prs = Presentation()\n",
    "    blank_slide_layout = prs.slide_layouts[6]  # layout tr·ªëng\n",
    "\n",
    "    def add_title_slide(title, subtitle):\n",
    "        slide = prs.slides.add_slide(prs.slide_layouts[0])\n",
    "        slide.shapes.title.text = title\n",
    "        slide.placeholders[1].text = subtitle\n",
    "        slide.placeholders[1].text_frame.word_wrap = True\n",
    "\n",
    "    def add_vertical_layout_slide(title, text):\n",
    "        slide = prs.slides.add_slide(blank_slide_layout)\n",
    "        shapes = slide.shapes\n",
    "\n",
    "        title_box = shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(1))\n",
    "        tf = title_box.text_frame\n",
    "        tf.clear()\n",
    "        tf.paragraphs[0].text = title\n",
    "        tf.paragraphs[0].font.size = Pt(36)\n",
    "        tf.paragraphs[0].font.bold = True\n",
    "\n",
    "        left = Inches(0.5)\n",
    "        top = Inches(1)\n",
    "        width = Inches(8.5)\n",
    "        add_bullets_with_equations(shapes, left, top, width, text)\n",
    "\n",
    "    def add_image_slide(title, text, images):\n",
    "        slide = prs.slides.add_slide(blank_slide_layout)\n",
    "        shapes = slide.shapes\n",
    "\n",
    "        title_box = shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(1))\n",
    "        tf = title_box.text_frame\n",
    "        tf.clear()\n",
    "        tf.paragraphs[0].text = title\n",
    "        tf.paragraphs[0].font.size = Pt(36)\n",
    "        tf.paragraphs[0].font.bold = True\n",
    "\n",
    "        # Text b√™n tr√°i, c√≥ ch√®n ·∫£nh equation d∆∞·ªõi bullet\n",
    "        left = Inches(0.5)\n",
    "        top = Inches(1)\n",
    "        width = Inches(4.3)\n",
    "        add_bullets_with_equations(shapes, left, top, width, text, max_image_width=Inches(3.5))\n",
    "\n",
    "        # ·∫¢nh th∆∞·ªùng (kh√¥ng ph·∫£i equation) b√™n ph·∫£i\n",
    "        y = 1\n",
    "        for img in images:\n",
    "            path = img['path']\n",
    "            caption = img.get('caption', '')\n",
    "            if not os.path.exists(path):\n",
    "                print(f\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y ·∫£nh: {path}\")\n",
    "                continue\n",
    "\n",
    "            pic = slide.shapes.add_picture(path, Inches(5.3), Inches(y), width=Inches(4))\n",
    "            pic_height = pic.height.inches\n",
    "\n",
    "            if caption:\n",
    "                caption_top = y + pic_height + 0.1\n",
    "                cap_box = slide.shapes.add_textbox(Inches(5.3), Inches(caption_top), Inches(4), Inches(0.6))\n",
    "                cap_tf = cap_box.text_frame\n",
    "                cap_tf.clear()\n",
    "                cap_tf.paragraphs[0].text = caption\n",
    "                cap_tf.paragraphs[0].font.size = Pt(12)\n",
    "\n",
    "            y = y + pic_height + 0.5\n",
    "\n",
    "    # === Duy·ªát t·ª´ng block ===\n",
    "    for i, block in enumerate(blocks):\n",
    "        title = block.get('heading', '')\n",
    "        text = block.get('text', '')\n",
    "        images = []\n",
    "\n",
    "        # Slide 0 - Title\n",
    "        if i == 0:\n",
    "            add_title_slide(title, text)\n",
    "\n",
    "        # # Slide 1 - Content\n",
    "        # elif i == 1:\n",
    "        #     add_vertical_layout_slide(title, text)\n",
    "        # Slide 1 - Content\n",
    "        elif i == 1:\n",
    "            slide = prs.slides.add_slide(blank_slide_layout)\n",
    "            shapes = slide.shapes\n",
    "            title_box = shapes.add_textbox(Inches(0.5), Inches(0.2), Inches(9), Inches(1))\n",
    "            tf = title_box.text_frame\n",
    "            tf.clear()\n",
    "            tf.paragraphs[0].text = title\n",
    "            tf.paragraphs[0].font.size = Pt(36)\n",
    "            tf.paragraphs[0].font.bold = True\n",
    "\n",
    "            content_box = shapes.add_textbox(Inches(0.5), Inches(1), Inches(8.5), Inches(5))\n",
    "            set_text_with_font(content_box.text_frame, text, 24)\n",
    "\n",
    "\n",
    "        # C√°c slide c√≤n l·∫°i\n",
    "        else:\n",
    "            # L·∫•y ·∫£nh th∆∞·ªùng (kh√¥ng c√≤n tr∆∞·ªùng equations n·ªØa)\n",
    "            if block.get('images'):\n",
    "                for img in block['images']:\n",
    "                    filename = os.path.basename(img['src'])\n",
    "                    full_path = os.path.join(\"/kaggle/working\", pdf_filename,\"auto/images\", filename)\n",
    "                    caption = img.get('caption', '')\n",
    "                    images.append({'path': full_path, 'caption': caption})\n",
    "\n",
    "            if images:\n",
    "                add_image_slide(title, text, images)\n",
    "            else:\n",
    "                add_vertical_layout_slide(title, text)\n",
    "\n",
    "    prs.save(output_file)\n",
    "    print(f\"‚úÖ File PowerPoint ƒë√£ ƒë∆∞·ª£c t·∫°o: {output_file}\")\n",
    "\n",
    "def create_slide(pdf_path, markdown_file, pdf_filename, middle_json, content_list_json, image_captions, table_captions, output_file=\"/kaggle/working/slides/slide_output.pptx\"):\n",
    "    #crop_equations_from_pdf(pdf_path, pdf_filename, middle_json)\n",
    "    copy_unique_equation_images(pdf_filename, middle_json)\n",
    "    blocks = parse_markdown(markdown_file, content_list_json, pdf_filename,image_captions, table_captions)\n",
    "    cleaned_blocks = update_levels_from_heading_text(blocks)\n",
    "    content_block = create_content_slide(cleaned_blocks)\n",
    "    cleaned_blocks.insert(1, content_block)\n",
    "\n",
    "    summarized_blocks = summarize_blocks(cleaned_blocks,2)\n",
    "\n",
    "    final_blocks  = []\n",
    "    final_blocks = [cleaned_blocks[0], cleaned_blocks[1]] + summarized_blocks\n",
    "\n",
    "    for i in range(2, len(final_blocks)):\n",
    "        block = final_blocks[i]\n",
    "        if \"text\" in block:\n",
    "            lines = block[\"text\"].split('\\n')\n",
    "            updated_lines = []\n",
    "\n",
    "            for line in lines:\n",
    "                stripped = line.strip()\n",
    "                if stripped.startswith(\"‚Ä¢\"):\n",
    "                    updated_lines.append(stripped)\n",
    "                elif stripped:\n",
    "                    updated_lines.append(\"‚Ä¢ \" + stripped)\n",
    "                else:\n",
    "                    updated_lines.append(\"\")  # d√≤ng tr·∫Øng gi·ªØ nguy√™n\n",
    "\n",
    "            block[\"text\"] = \"\\n\".join(updated_lines)\n",
    "\n",
    "    create_presentation(final_blocks, pdf_filename, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%writefile gradio_app.py\n",
    "import gradio as gr\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "import tempfile\n",
    "from pdf2image import convert_from_path\n",
    "import base64\n",
    "from extract_pdf import extract_pdf\n",
    "from process_json_data import process_json_data\n",
    "from create_slide import create_slide\n",
    "from reranker import get_top_k_docs\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "import time\n",
    "from PIL import Image\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "# Gemini API\n",
    "from google import genai\n",
    "class GeminiClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "    def generate_content(self, prompt, model=\"gemini-2.0-flash\"):\n",
    "        response = self.client.models.generate_content(model=model, contents=prompt)\n",
    "        return response.text.strip()\n",
    "\n",
    "# Kh·ªüi t·∫°o embedding\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "\n",
    "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\"\n",
    "gemini_client = GeminiClient(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Session state\n",
    "chat_history = []\n",
    "global_context = {}\n",
    "\n",
    "def build_prompt(context, question):\n",
    "    context_text = \"\\n\".join([doc[\"document\"] for doc in context])\n",
    "    return f\"\"\"\n",
    "You are given a context that may contain both relevant and irrelevant information. Your task is to answer the question using **only** the most relevant information from the context.\n",
    "\n",
    "Return your answer in **Markdown format**, suitable for rendering in Gradio using `gr.Markdown(...)`.\n",
    "\n",
    "If your answer contains mathematical expressions, use **LaTeX syntax** within `$$ ... $$` for block equations, and `$ ... $` for inline math.  \n",
    "Avoid using any HTML tags like `<sub>`, `<sup>`, or `<b>`.\n",
    "\n",
    "Use:\n",
    "- `\\\\sum`, `\\\\left(`, `\\\\right)`, `\\\\| \\\\cdot \\\\|_2^2`, etc., for math formatting.\n",
    "- Lists or headings for structuring your answer if needed.\n",
    "\n",
    "Response in **English**\n",
    "---\n",
    "**Context**:\n",
    "{context_text}\n",
    "\n",
    "**Question**:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def process_pdf(uploaded_file):\n",
    "    # L·∫•y t√™n g·ªëc\n",
    "    basename = os.path.basename(uploaded_file.name)\n",
    "\n",
    "    # Copy gi·ªØ t√™n g·ªëc\n",
    "    save_dir = \"/kaggle/working/uploaded\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(save_dir, basename)\n",
    "    shutil.copy(uploaded_file.name, pdf_path)\n",
    "\n",
    "    # pdf_filename = basename.replace(\".pdf\", \"\")\n",
    "\n",
    "    images = convert_from_path(pdf_path, dpi=300)\n",
    "    \n",
    "    html_images = \"\"\n",
    "\n",
    "    for idx, img in enumerate(images, start=1):\n",
    "        # Resize ·∫£nh v·ªÅ 1200px chi·ªÅu ngang ƒë·ªÉ gi·ªØ ƒë·ªô n√©t, d√πng LANCZOS cho ch·∫•t l∆∞·ª£ng cao\n",
    "        target_width = 1200\n",
    "        img = img.resize((target_width, int(target_width * img.height / img.width)), Image.LANCZOS)\n",
    "    \n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".png\") as img_file:\n",
    "            img.save(img_file.name, \"PNG\")\n",
    "            with open(img_file.name, \"rb\") as f:\n",
    "                b64 = base64.b64encode(f.read()).decode()\n",
    "    \n",
    "                # Th√™m s·ªë trang tr∆∞·ªõc m·ªói ·∫£nh v√† hi·ªÉn th·ªã ·∫£nh k√≠ch th∆∞·ªõc nh·ªè h∆°n\n",
    "                html_images += f'''\n",
    "                <div style=\"margin-bottom: 20px;\">\n",
    "                    <div style=\"font-weight: bold; text-align: center; margin-bottom: 5px;\">Page {idx}</div>\n",
    "                    <img src=\"data:image/png;base64,{b64}\" \n",
    "                         style=\"width:auto; height:auto;\" />\n",
    "                </div>\n",
    "                '''\n",
    "    \n",
    "    html_output = f'''\n",
    "    <div style=\"max-height: 800px; overflow: auto; border: 1px solid #ccc; padding: 5px;\">\n",
    "        {html_images}\n",
    "    </div>\n",
    "'''\n",
    "\n",
    "    pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    #pdf_filename = os.path.basename(saved_path).split(\".\")[0]\n",
    "    # jsons_dir = os.path.join(\"/kaggle/working/output\", \"jsons\")\n",
    "    # images_dir = os.path.join(\"/kaggle/working/output\", \"images\")\n",
    "    # json_folder = os.path.join(jsons_dir, pdf_filename)\n",
    "    # images_folder = os.path.join(images_dir, pdf_filename)\n",
    "\n",
    "    root = os.path.join(\"/kaggle/working\", pdf_filename, \"auto\")\n",
    "    os.makedirs(\"/kaggle/working/output/pkl\", exist_ok=True)\n",
    "    pkl_path = os.path.join(\"/kaggle/working/output/pkl\", f\"{pdf_filename}.pkl\")\n",
    "    \n",
    "    markdown_file = os.path.join(root, f\"{pdf_filename}.md\")\n",
    "    middle_json = os.path.join(root, f\"{pdf_filename}_middle.json\")\n",
    "    content_list_json = os.path.join(root, f\"{pdf_filename}_content_list.json\")\n",
    "\n",
    "    images_folder = os.path.join(root, \"images\")\n",
    "\n",
    "    if not os.path.exists(root):\n",
    "        extract_pdf(pdf_path)\n",
    "        all_docs_summary, image_captions, table_captions = process_json_data(content_list_json, root)\n",
    "        with open(pkl_path, \"wb\") as f:\n",
    "            pickle.dump(all_docs_summary, f)\n",
    "    else:\n",
    "        all_docs_summary, image_captions, table_captions = process_json_data(content_list_json, root)\n",
    "        with open(pkl_path, \"wb\") as f:\n",
    "            pickle.dump(all_docs_summary, f)\n",
    "            \n",
    "    global_context[\"pdf_filename\"] = pdf_filename\n",
    "    global_context[\"pdf_path\"] = pdf_path\n",
    "    global_context[\"markdown_file\"] = markdown_file\n",
    "    global_context[\"middle_json\"] = middle_json\n",
    "    global_context[\"content_list_json\"] = content_list_json\n",
    "    global_context[\"all_docs_summary\"] = all_docs_summary\n",
    "    global_context[\"chroma_path\"] = f\"./chroma_db/{pdf_filename}\"\n",
    "    global_context[\"image_captions\"] = image_captions\n",
    "    global_context[\"table_captions\"] = table_captions\n",
    "\n",
    "    return html_output, \"PDF processed. You can now chat or create slide.\"\n",
    "\n",
    "def create_slide_and_download():\n",
    "    slide_path = \"/kaggle/working/slides/slide_output.pptx\"\n",
    "    os.makedirs(\"/kaggle/working/slides\", exist_ok=True)\n",
    "    create_slide(global_context[\"pdf_path\"], global_context[\"markdown_file\"],\n",
    "                 global_context[\"pdf_filename\"],\n",
    "                 global_context[\"middle_json\"],\n",
    "                 global_context[\"content_list_json\"],\n",
    "                 global_context[\"image_captions\"], \n",
    "                 global_context[\"table_captions\"])\n",
    "    \n",
    "    if os.path.exists(slide_path):\n",
    "        return slide_path, \"‚úÖ ƒê√£ t·∫°o xong slide, c√≥ th·ªÉ t·∫£i xu·ªëng.\"\n",
    "    else:\n",
    "        return None, \"‚ùå Slide ch∆∞a ƒë∆∞·ª£c t·∫°o.\"\n",
    "\n",
    "def chatbot_response(user_query, top_k):\n",
    "    all_docs_summary = global_context[\"all_docs_summary\"]\n",
    "    chroma_path = global_context[\"chroma_path\"]\n",
    "    #embeddings = OllamaEmbeddings(model=\"bge-m3\", base_url=\"http://localhost:11434\")\n",
    "    if os.path.exists(chroma_path):\n",
    "        chroma_db = Chroma(persist_directory=chroma_path, embedding_function=embeddings)\n",
    "    else:\n",
    "        chroma_db = Chroma.from_documents(all_docs_summary, embeddings, persist_directory=chroma_path)\n",
    "\n",
    "    retriever_chroma = chroma_db.as_retriever(search_kwargs={\"k\": 10})\n",
    "    bm25_retriever = BM25Retriever.from_documents(all_docs_summary)\n",
    "    bm25_retriever.k = 10\n",
    "    ensemble = EnsembleRetriever(retrievers=[bm25_retriever, retriever_chroma], weights=[0.6, 0.4])\n",
    "\n",
    "    context = get_top_k_docs(user_query, all_docs_summary, k=top_k)\n",
    "    prompt = build_prompt(context, user_query)\n",
    "    response = gemini_client.generate_content(prompt)\n",
    "\n",
    "    chat_history.append((user_query, response))\n",
    "\n",
    "    # ƒê·ªãnh d·∫°ng Markdown r√µ r√†ng h∆°n\n",
    "    formatted_response = f\"### Answer:\\n{response}\"\n",
    "    context_display = \"### Context:\\n\" + \"\\n\\n\".join([f\"**Doc {i+1}**:\\n{doc['document']}\" for i, doc in enumerate(context)])\n",
    "    \n",
    "    return formatted_response, chat_history, context_display\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks(css=\"body { background-color: #1e1e1e; color: white; }\") as demo:\n",
    "    gr.Markdown(\"## üìÑ Chat with PDF & Create Slide\")\n",
    "\n",
    "    with gr.Row():\n",
    "        # C·ªôt tr√°i\n",
    "        with gr.Column(scale=1):\n",
    "            pdf_file = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
    "            pdf_images_html = gr.HTML(label=\"PDF Pages (Scroll vertical)\", elem_id=\"pdf-images-scroll\", \n",
    "                                      visible=True)\n",
    "            status_text = gr.Textbox(label=\"Status\", interactive=False)\n",
    "\n",
    "            pdf_file.change(fn=process_pdf, inputs=pdf_file, outputs=[pdf_images_html, status_text])\n",
    "\n",
    "            slide_btn = gr.Button(\"üõ†Ô∏è Create Slide\")\n",
    "            slide_download = gr.File(label=\"üì• Download Slide\")\n",
    "            slide_status = gr.Textbox(label=\"Slide Status\", interactive=False)\n",
    "\n",
    "            slide_btn.click(fn=create_slide_and_download,\n",
    "                            outputs=[slide_download, slide_status])\n",
    "            \n",
    "            # Chat History chuy·ªÉn v√†o c·ªôt tr√°i, d∆∞·ªõi slide\n",
    "            chatbox = gr.Chatbot(label=\"üí¨ Chat History\", height=300)\n",
    "\n",
    "        # C·ªôt ph·∫£i\n",
    "        with gr.Column(scale=1):\n",
    "            chatbot_in = gr.Textbox(label=\"Your question\")\n",
    "            top_k_slider = gr.Slider(1, 10, value=3, step=1, label=\"Top-K Docs\")\n",
    "            chatbot_out = gr.Markdown(label=\"üß† AI Response\")\n",
    "            context_out = gr.Markdown(label=\"üìÑ Context used\")\n",
    "\n",
    "            chatbot_in.submit(fn=chatbot_response,\n",
    "                              inputs=[chatbot_in, top_k_slider],\n",
    "                              outputs=[chatbot_out, chatbox, context_out])\n",
    "\n",
    "demo.launch(server_name=\"0.0.0.0\", server_port=7860)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !ollama pull bge-m3\n",
    "!python gradio_app.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7675864,
     "sourceId": 12186604,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
